{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGmTJl62p_-C"
      },
      "outputs": [],
      "source": [
        "#Logistic Regression with data perturbation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "aAXMgTY8rQvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"/content/conservation_dataset.csv\")\n",
        "df_cl=df.drop(columns=['Unnamed: 0','user id'])\n",
        "df_cl=df_cl[\"engaged\"]=df_cl['engaged'].astype(int)"
      ],
      "metadata": {
        "id": "xmvD_B3PsdOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df)"
      ],
      "metadata": {
        "id": "p3v6uCQ0-QJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/conservation_dataset.csv\")\n",
        "\n",
        "# Drop unnecessary columns\n",
        "df_cl = df.drop(columns=['Unnamed: 0', 'user id'])\n",
        "\n",
        "# Convert 'engaged' column to int (assuming it's binary: 0 or 1)\n",
        "df_cl['engaged'] = df_cl['engaged'].astype(int)\n",
        "\n",
        "# Define features and target\n",
        "X_raw = df_cl.drop(columns=['engaged'])\n",
        "y = df_cl['engaged']\n",
        "\n",
        "# Define categorical and numerical columns\n",
        "cat_cols = ['message_type', 'most engagement day']\n",
        "num_cols = ['total_messages_seen', 'most engagement hour']\n",
        "\n",
        "# One-hot encode categorical variables\n",
        "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "X_cat = encoder.fit_transform(X_raw[cat_cols])\n",
        "\n",
        "# Convert numerical columns to NumPy array\n",
        "X_num = X_raw[num_cols].values\n",
        "\n",
        "# Combine categorical and numerical features\n",
        "X_combined = np.hstack([X_num, X_cat])\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_combined)"
      ],
      "metadata": {
        "id": "eBXghU-SvB-U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def per_data(X,noise_std=0.1,num_per=1):\n",
        "  per_X=[X]\n",
        "  for i in range(num_per):\n",
        "    noise=np.random.normal(loc=0.0,scale=noise_std,size=X.shape)\n",
        "    per_X.append(X + noise)\n",
        "  return np.vstack(per_X)"
      ],
      "metadata": {
        "id": "jZyg8HuZwx8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train,X_test,y_train,y_test=train_test_split(X_scaled,y,test_size=0.2,random_state=42)\n",
        "\n",
        "X_train_aug = per_data(X_train,noise_std=0.1,num_per=1)\n",
        "y_train_aug = np.tile(y_train,2)\n",
        "\n",
        "model = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
        "model.fit(X_train_aug,y_train_aug)"
      ],
      "metadata": {
        "id": "UAYqsvMuyQd1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test,y_pred)\n",
        "print(f\"Test Accuracy: { accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "5eC9TiP3ziZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression using sigmoid function with its derivative"
      ],
      "metadata": {
        "id": "Q2-6kxKQEGKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
        "\n",
        "df = pd.read_csv(\"/content/conservation_dataset.csv\")\n",
        "\n",
        "df_cl = df.drop(columns=['Unnamed: 0', 'user id'])\n",
        "\n",
        "df_cl['engaged'] = df_cl['engaged'].astype(int)\n",
        "\n",
        "\n",
        "X_raw = df_cl.drop(columns=['engaged'])\n",
        "y = df_cl['engaged'].values\n",
        "\n",
        "\n",
        "cat_cols = ['message_type', 'most engagement day']\n",
        "num_cols = ['total_messages_seen', 'most engagement hour']\n",
        "\n",
        "\n",
        "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "X_cat = encoder.fit_transform(X_raw[cat_cols])\n",
        "\n",
        "\n",
        "X_num = X_raw[num_cols].values\n",
        "\n",
        "\n",
        "X_combined = np.hstack([X_num, X_cat])\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_combined)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "def predict(X, weights):\n",
        "    z = np.dot(X, weights)\n",
        "    return sigmoid(z)\n",
        "\n",
        "def binary_cross_entropy(y_true, y_pred):\n",
        "    epsilon = 1e-15\n",
        "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
        "    return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))\n",
        "\n",
        "\n",
        "def train_logistic_regression(X, y, lr=0.1, epochs=1000):\n",
        "    weights = np.zeros(X.shape[1])\n",
        "    for epoch in range(epochs):\n",
        "        y_pred = predict(X, weights)\n",
        "        error = y_pred - y\n",
        "        gradient = np.dot(X.T, error) / len(y)\n",
        "        weights -= lr * gradient\n",
        "    return weights\n",
        "\n",
        "\n",
        "weights = train_logistic_regression(X_train, y_train)\n",
        "\n",
        "\n",
        "y_prob = predict(X_test, weights)\n",
        "y_pred = (y_prob >= 0.5).astype(int)\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, zero_division=0)\n",
        "recall = recall_score(y_test, y_pred, zero_division=0)\n",
        "f1 = f1_score(y_test, y_pred, zero_division=0)\n",
        "\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n"
      ],
      "metadata": {
        "id": "0nFOkz6SEJSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Using SoftMax Regression"
      ],
      "metadata": {
        "id": "t1SPNhS9FUBX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_fscore_support\n",
        "\n",
        "\n",
        "df = pd.read_csv(\"/content/conservation_dataset.csv\")\n",
        "\n",
        "\n",
        "df_cl = df.drop(columns=['Unnamed: 0', 'user id'])\n",
        "\n",
        "\n",
        "y = df_cl['engaged'].astype(int).values\n",
        "X_raw = df_cl.drop(columns=['engaged'])\n",
        "\n",
        "\n",
        "cat_cols = ['message_type', 'most engagement day']\n",
        "num_cols = ['total_messages_seen', 'most engagement hour']\n",
        "\n",
        "\n",
        "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "X_cat = encoder.fit_transform(X_raw[cat_cols])\n",
        "X_num = X_raw[num_cols].values\n",
        "\n",
        "\n",
        "X_combined = np.hstack([X_num, X_cat])\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_combined)\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "\n",
        "\n",
        "def softmax(z):\n",
        "    exp_z = np.exp(z - np.max(z, axis=1, keepdims=True))\n",
        "    return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
        "\n",
        "def one_hot(y, num_classes):\n",
        "    return np.eye(num_classes)[y]\n",
        "\n",
        "def cross_entropy_loss(y_true, y_pred):\n",
        "    epsilon = 1e-15\n",
        "    y_pred = np.clip(y_pred, epsilon, 1 - epsilon)\n",
        "    return -np.mean(np.sum(y_true * np.log(y_pred), axis=1))\n",
        "\n",
        "def train_softmax(X, y, lr=0.1, epochs=1000):\n",
        "    num_samples, num_features = X.shape\n",
        "    num_classes = np.max(y) + 1\n",
        "    y_onehot = one_hot(y, num_classes)\n",
        "    weights = np.zeros((num_features, num_classes))\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        logits = np.dot(X, weights)\n",
        "        probs = softmax(logits)\n",
        "        gradient = np.dot(X.T, (probs - y_onehot)) / num_samples\n",
        "        weights -= lr * gradient\n",
        "\n",
        "    return weights\n",
        "\n",
        "def predict_softmax(X, weights):\n",
        "    logits = np.dot(X, weights)\n",
        "    probs = softmax(logits)\n",
        "    return np.argmax(probs, axis=1), probs\n",
        "\n",
        "\n",
        "weights = train_softmax(X_train, y_train)\n",
        "\n",
        "\n",
        "y_pred, y_prob = predict_softmax(X_test, weights)\n",
        "\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted', zero_division=0)\n",
        "\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n"
      ],
      "metadata": {
        "id": "SmmTPWaIFauM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}