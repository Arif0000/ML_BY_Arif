{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V5E1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "v1-GiUueeh8U"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import math\n",
        "\n",
        "def tokenize(text, vocab):\n",
        "  return [vocab.get(word, vocab[\"<UNK>\"]) for word in text.split()]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Embedding(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim):\n",
        "    super(Embedding, self).__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "  def forward(self, x):\n",
        "    return self.embedding(x)\n",
        "\n"
      ],
      "metadata": {
        "id": "e4Z04gTE6qwY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "  def __init__(self, embedding_dim, max_seq_len=5000):\n",
        "    super(PositionalEncoding,self).__init__()\n",
        "    self.embedding_dim = embedding_dim\n",
        "    pe = torch.zeros(max_seq_len, embedding_dim)\n",
        "    position = torch.arange(0,max_seq_len, dtype=torch.float).unsqueeze(1)\n",
        "    div_term = torch.exp(torch.arange(0, embedding_dim,2).float() * (-math.log(10000.0)/ embedding_dim))\n",
        "    pe[:, 0::2] = torch.sin(position * div_term)\n",
        "    pe[:, 1::2] = torch.cos(position * div_term)\n",
        "    pe = pe.unsqueeze(0).transpose(0,1)\n",
        "    self.register_buffer('pe', pe)\n",
        "  def forward(self, x):\n",
        "    return x + self.pe[:x.size(0),:]\n"
      ],
      "metadata": {
        "id": "0DTUXdNs7jDh"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch._C import Value\n",
        "class SelfAttention(nn.Module):\n",
        "  def __init__(self, embedding_dim):\n",
        "    super(SelfAttention, self).__init__()\n",
        "    self.query = nn.Linear(embedding_dim,embedding_dim)\n",
        "    self.key = nn.Linear(embedding_dim, embedding_dim)\n",
        "    self.value = nn.Linear(embedding_dim,embedding_dim)\n",
        "\n",
        "  def forward(self, x):\n",
        "    queries = self.query(x)\n",
        "    keys = self.key(x)\n",
        "    Values = self.value(x)\n",
        "    scores = torch.bmm(queries, keys.transpose(1/2))/ troch.sqrt(torch.tensor(x.size(-1), dtype=torch.float32))\n",
        "    attention_weights = torch.softmax(scores, dim=-1)\n",
        "    attention_values = torch.bmm(attention_weights, values)\n",
        "    return attention_values"
      ],
      "metadata": {
        "id": "m7UUiEOdBPx-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "  def __init__(self, embedding_dim,hidden_dim):\n",
        "    super(TransformerBlock, self).__init__()\n",
        "    self.attention = SelfAttention(embedding_dim)\n",
        "    self.feed_forward = nn.Sequential(nn.Linear(embedding_dim, hidden_dim),nn.ReLU(), nn.Linear(hidden_dim, embedding_dim))\n",
        "    self.norm1 = nn.LayerNorm(embedding_dim)\n",
        "    self.norm2 = nn.LayerNorm(embedding_dim)\n",
        "  def forward(self, x):\n",
        "    attention = self.attention(x)\n",
        "    x = self.norm1(x + attention)\n",
        "    forwarded = self.feed_forward(x)\n",
        "    x = self.norm2(x + forwarded)\n",
        "    return x\n"
      ],
      "metadata": {
        "id": "nJawIKoZEVEl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleLLM(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers):\n",
        "    super(SimpleLLM, self).__init__()\n",
        "    self.embedding = Embedding(vocab_size, embedding_dim)\n",
        "    self.positional_encoding = PositionalEncoding(embedding_dim)\n",
        "    self.transformer_blocks = nn.Sequential(*[TransformerBlock(embedding_dim,hidden_dim) for _ in range(num_layers)])\n",
        "    self.output = nn.Linear(embedding_dim, vocab_size)\n",
        "  def forward(self,x):\n",
        "    x = self.embedding(x)\n",
        "    x = x.transpose(0,1)\n",
        "    x = self.positional_encoding(x)\n",
        "    x = x.transpose(0,1)\n",
        "    x = self.transformer_blocks(x)\n",
        "    x = self.output(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "EqM1aLIVirWs"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = {\"hello\":0,\"world\":1,\"how\":2,\"are\":3,\"you\":4,\"<UNK>\":5}\n",
        "vocab_size = len(vocab)\n",
        "embedding_dim = 16\n",
        "hidden_dim = 32\n",
        "num_layer = 2\n",
        "\n",
        "model = SimpleLLM(vocab_size, embedding_dim, hidden_dim, num_layer)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "data = [\"hello world how are you\",\"how are you hello world\"]\n",
        "tokenized_data = [tokenize(sentence, vocab) for sentence in data]\n",
        "\n",
        "for epoch in range(100):\n",
        "    total_loss = 0\n",
        "\n",
        "    for sentence in tokenized_data:\n",
        "        for i in range(1, len(sentence)):\n",
        "            input_seq = torch.tensor(sentence[:i]).unsqueeze(0)\n",
        "            target = torch.tensor(sentence[i]).unsqueeze(0)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            output = model(input_seq)\n",
        "\n",
        "            loss = criterion(output[:, -1, :], target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch {epoch}, Loss: {total_loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoqvNhvrpMTG",
        "outputId": "c5584f46-5473-4f30-d31e-25daf8e88b6f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 15.0987\n",
            "Epoch 10, Loss: 10.7659\n",
            "Epoch 20, Loss: 6.0740\n",
            "Epoch 30, Loss: 3.0810\n",
            "Epoch 40, Loss: 1.6915\n",
            "Epoch 50, Loss: 0.7919\n",
            "Epoch 60, Loss: 0.4311\n",
            "Epoch 70, Loss: 0.2767\n",
            "Epoch 80, Loss: 0.1944\n",
            "Epoch 90, Loss: 0.1445\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"hello world how\"\n",
        "input_tokens = tokenize(input_text, vocab)\n",
        "input_tensor = torch.tensor(input_tokens).unsqueeze(0)\n",
        "\n",
        "output = model(input_tensor)\n",
        "predicted_token = torch.argmax(output[:, -1, :], dim=-1).item()\n",
        "\n",
        "inv_vocab = {v: k for k, v in vocab.items()}\n",
        "predicted_word = inv_vocab[predicted_token]\n",
        "\n",
        "print(f\"Input: {input_text}, Predicted: {predicted_word}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xto6CSZgtdu7",
        "outputId": "b3c9c8ce-c214-4d1f-f312-69f8399b2b7f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: hello world how, Predicted: are\n"
          ]
        }
      ]
    }
  ]
}